{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns                   #veri görselleştirilmesi için kullanılır\n",
    "import matplotlib.pyplot as plt         #veri görselleştirilmesi için kullanılır\n",
    "data_train=pd.read_csv(\"train.csv\")     #csv dosyalarını okumak için kullanılır\n",
    "data_test=pd.read_csv(\"test.csv\")       #csv dosyalarını okumak için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Machine failure']=np.nan     #test verisine \"Machine failure\" adında boş bir stun eklemek için kullanılmış\n",
    "data_train['data']='train'              #data adında yeni bir stun eklen\n",
    "data_test['data']='test'                #data adında yeni bir stun eklen\n",
    "data_test=data_test[data_train.columns] #eğitim ve test verilerinin aynı sütun numarasına sahip olması sağlanmış"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = [                                                    #orjinal stun adlarını belirlemek için kullanılmış\n",
    "    'Air temperature [K]',\n",
    "    'Process temperature [K]',\n",
    "    'Rotational speed [rpm]',\n",
    "    'Torque [Nm]',\n",
    "    'Tool wear [min]'\n",
    "]\n",
    "\n",
    "new_columns = {col: col.split(' [')[0] for col in original_columns}     #yeni stun oluşturup stün adlarını daha anlamlı hale getirmek için kullanılır\n",
    "data_train = data_train.rename(columns=new_columns)                     #data_train stün adlarıonı yeni stun isimleriyle değiştirir\n",
    "\n",
    "data_test = data_test.rename(columns=new_columns)                       #aynı işlemi data_test içinde yapar\n",
    "#print(data_test.columns)                                               #yapılan işlemlerin kontrolü sağlanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([data_train,data_test],axis=0)                       #Bütün verileri birleştirmek için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "Product ID             0\n",
       "Type                   0\n",
       "Air temperature        0\n",
       "Process temperature    0\n",
       "Rotational speed       0\n",
       "Torque                 0\n",
       "Tool wear              0\n",
       "Machine failure        0\n",
       "TWF                    0\n",
       "HDF                    0\n",
       "PWF                    0\n",
       "OSF                    0\n",
       "RNF                    0\n",
       "data                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isna().sum()                                                 #verilerimizde boş biryer olup olmadığı koıntrol edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0.0    134281\n",
       "1.0      2148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['Machine failure'].value_counts()              #stünun içindeki hatalarıun sayısını belirlenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.51443202979516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "134281/2148                                             #cihazın hata verme oranı hesaplanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', dtype('int64'), 227383),\n",
       " ('Product ID', dtype('O'), 9995),\n",
       " ('Type', dtype('O'), 3),\n",
       " ('Air temperature', dtype('float64'), 95),\n",
       " ('Process temperature', dtype('float64'), 84),\n",
       " ('Rotational speed', dtype('int64'), 974),\n",
       " ('Torque', dtype('float64'), 628),\n",
       " ('Tool wear', dtype('int64'), 246),\n",
       " ('Machine failure', dtype('float64'), 2),\n",
       " ('TWF', dtype('int64'), 2),\n",
       " ('HDF', dtype('int64'), 2),\n",
       " ('PWF', dtype('int64'), 2),\n",
       " ('OSF', dtype('int64'), 2),\n",
       " ('RNF', dtype('int64'), 2),\n",
       " ('data', dtype('O'), 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(data_all.columns,data_all.dtypes,data_all.nunique()))          #bütün değerler hesaplanır sırasıyla stün ismi, typı, kaç tane farklı değer olduğu hesaplanmıştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=pd.get_dummies(data_all['Type'], drop_first=False)                #type stunundaki değerleri binary olarak dönüştürür (0 ve 1) (True or False)\n",
    "\n",
    "#bunun yerine label encoder kullanılabilirdi\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le=LabelEncoder()\n",
    "\n",
    "#LeColum=\"Type\"\n",
    "#LeColum2=\"Product ID\"\n",
    "#data_all[LeColum] = le.fit_transform(data_all[LeColum])\n",
    "#data_all[LeColum2] = le.fit_transform(data_all[LeColum2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_boolean = {True: 1, False: 0}                           #boolean değerlerini 0 ve 1 e dönüştürür\n",
    "types['H'] = types['H'].map(mapping_boolean)\n",
    "types['L'] = types['L'].map(mapping_boolean)\n",
    "types['M'] = types['M'].map(mapping_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([data_all, types], axis=1)                   #dönüştürülen boolean verisini bütün tabloya ekler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.drop(['id', 'Product ID', 'Type'], axis=1, inplace=True)   #bütün veriden id product id ve typı siler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basri\\AppData\\Local\\Temp\\ipykernel_26204\\1697743391.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test.drop(['Machine failure','data'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_train=data_all[data_all['data']=='train']                      #data stünunun içndeki train olanları seçer\n",
    "del data_train['data']                                              #data stununu kaldırır\n",
    "data_test=data_all[data_all['data']=='test']                        #data stünunun içndeki test olanları seçer\n",
    "data_test.drop(['Machine failure','data'],axis=1,inplace=True)      #'Machine failure','data' stunlarını kaldırır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                                    #veriyi eğitim ve test kümelerine bölen bir fonksiyon çağırır\n",
    "\n",
    "X = data_train.drop(columns=\"Machine failure\")                                          #tahmin etmemizi istedikleri veri Machine daillure olduğu için bu veri çıkartılır\n",
    "y = data_train[\"Machine failure\"]                                                       #tahmin edeceğimiz veri ayrı seçilir\n",
    "\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,random_state=0)       #train test kümelerine ayırır verinin %25 i test için ayırır random_state ise seed vermek için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102321, 13), (34108, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape              #ayrılan verilerin şeklini verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler          #veriyi daha rahat işlemesi için bir aralığa sıkıştırır veri 0 ile 1 arasında olur\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val= scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation ROC-AUC: 0.9527\n",
      "Random Forest Cross-Validation ROC-AUC: 0.9398\n",
      "KNN Cross-Validation ROC-AUC: 0.8889\n",
      "Logistic Regression Cross-Validation ROC-AUC: 0.9328\n",
      "Decision Tree Cross-Validation ROC-AUC: 0.8821\n",
      "SVM Cross-Validation ROC-AUC: 0.9151\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()                                                                     #veri XGBClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'XGBoost Cross-Validation ROC-AUC: {xgb_scores.mean():.4f}')\n",
    "\n",
    "rf_model = RandomForestClassifier()                                                                 #veri RandomForestClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Random Forest Cross-Validation ROC-AUC: {rf_scores.mean():.4f}')\n",
    "\n",
    "knn_model = KNeighborsClassifier()                                                                  #veri KNeighborsClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "knn_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'KNN Cross-Validation ROC-AUC: {knn_scores.mean():.4f}')\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight = 'balanced')                                        #veri LogisticRegression kullanılarak eğitilir ve sonuç print edilir\n",
    "logreg_scores = cross_val_score(logreg_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Logistic Regression Cross-Validation ROC-AUC: {logreg_scores.mean():.4f}')\n",
    "\n",
    "dt_model = DecisionTreeClassifier()                                                                 #veri DecisionTreeClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "dt_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Decision Tree Cross-Validation ROC-AUC: {dt_scores.mean():.4f}')\n",
    "\n",
    "svm_model = SVC(probability=True)                                                                   #veri SVC kullanılarak eğitilir ve sonuç print edilir\n",
    "svm_scores = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'SVM Cross-Validation ROC-AUC: {svm_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_val)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
