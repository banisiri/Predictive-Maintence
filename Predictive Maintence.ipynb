{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns                   #veri görselleştirilmesi için kullanılır\n",
    "import matplotlib.pyplot as plt         #veri görselleştirilmesi için kullanılır\n",
    "data_train=pd.read_csv(\"train.csv\")     #csv dosyalarını okumak için kullanılır\n",
    "data_test=pd.read_csv(\"test.csv\")       #csv dosyalarını okumak için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Machine failure']=np.nan     #test verisine \"Machine failure\" adında boş bir stun eklemek için kullanılmış\n",
    "data_train['data']='train'              #data adında yeni bir stun eklen\n",
    "data_test['data']='test'                #data adında yeni bir stun eklen\n",
    "data_test=data_test[data_train.columns] #eğitim ve test verilerinin aynı sütun numarasına sahip olması sağlanmış"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = [                                                    #orjinal stun adlarını belirlemek için kullanılmış\n",
    "    'Air temperature [K]',\n",
    "    'Process temperature [K]',\n",
    "    'Rotational speed [rpm]',\n",
    "    'Torque [Nm]',\n",
    "    'Tool wear [min]'\n",
    "]\n",
    "\n",
    "new_columns = {col: col.split(' [')[0] for col in original_columns}     #yeni stun oluşturup stün adlarını daha anlamlı hale getirmek için kullanılır\n",
    "data_train = data_train.rename(columns=new_columns)                     #data_train stün adlarıonı yeni stun isimleriyle değiştirir\n",
    "\n",
    "data_test = data_test.rename(columns=new_columns)                       #aynı işlemi data_test içinde yapar\n",
    "#print(data_test.columns)                                               #yapılan işlemlerin kontrolü sağlanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([data_train,data_test],axis=0)                       #Bütün verileri birleştirmek için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "Product ID             0\n",
       "Type                   0\n",
       "Air temperature        0\n",
       "Process temperature    0\n",
       "Rotational speed       0\n",
       "Torque                 0\n",
       "Tool wear              0\n",
       "Machine failure        0\n",
       "TWF                    0\n",
       "HDF                    0\n",
       "PWF                    0\n",
       "OSF                    0\n",
       "RNF                    0\n",
       "data                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isna().sum()                                                 #verilerimizde boş biryer olup olmadığı koıntrol edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0.0    134281\n",
       "1.0      2148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['Machine failure'].value_counts()              #stünun içindeki hatalarıun sayısını belirlenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.51443202979516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "134281/2148                                             #cihazın hata verme oranı hesaplanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', dtype('int64'), 227383),\n",
       " ('Product ID', dtype('O'), 9995),\n",
       " ('Type', dtype('O'), 3),\n",
       " ('Air temperature', dtype('float64'), 95),\n",
       " ('Process temperature', dtype('float64'), 84),\n",
       " ('Rotational speed', dtype('int64'), 974),\n",
       " ('Torque', dtype('float64'), 628),\n",
       " ('Tool wear', dtype('int64'), 246),\n",
       " ('Machine failure', dtype('float64'), 2),\n",
       " ('TWF', dtype('int64'), 2),\n",
       " ('HDF', dtype('int64'), 2),\n",
       " ('PWF', dtype('int64'), 2),\n",
       " ('OSF', dtype('int64'), 2),\n",
       " ('RNF', dtype('int64'), 2),\n",
       " ('data', dtype('O'), 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(data_all.columns,data_all.dtypes,data_all.nunique()))          #bütün değerler hesaplanır sırasıyla stün ismi, typı, kaç tane farklı değer olduğu hesaplanmıştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=pd.get_dummies(data_all['Type'], drop_first=False)                #type stunundaki değerleri binary olarak dönüştürür (0 ve 1) (True or False)\n",
    "\n",
    "#bunun yerine label encoder kullanılabilirdi\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le=LabelEncoder()\n",
    "\n",
    "#LeColum=\"Type\"\n",
    "#LeColum2=\"Product ID\"\n",
    "#data_all[LeColum] = le.fit_transform(data_all[LeColum])\n",
    "#data_all[LeColum2] = le.fit_transform(data_all[LeColum2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_boolean = {True: 1, False: 0}                           #boolean değerlerini 0 ve 1 e dönüştürür\n",
    "types['H'] = types['H'].map(mapping_boolean)\n",
    "types['L'] = types['L'].map(mapping_boolean)\n",
    "types['M'] = types['M'].map(mapping_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([data_all, types], axis=1)                   #dönüştürülen boolean verisini bütün tabloya ekler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.drop(['id', 'Product ID', 'Type'], axis=1, inplace=True)   #bütün veriden id product id ve typı siler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basri\\AppData\\Local\\Temp\\ipykernel_13268\\455916649.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test.drop(['Machine failure','data'],axis=1,inplace=True)      #'Machine failure','data' stunlarını kaldırır\n"
     ]
    }
   ],
   "source": [
    "data_train=data_all[data_all['data']=='train']                      #data stünunun içndeki train olanları seçer\n",
    "del data_train['data']                                              #data stununu kaldırır\n",
    "data_test=data_all[data_all['data']=='test']                        #data stünunun içndeki test olanları seçer\n",
    "data_test.drop(['Machine failure','data'],axis=1,inplace=True)      #'Machine failure','data' stunlarını kaldırır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                                    #veriyi eğitim ve test kümelerine bölen bir fonksiyon çağırır\n",
    "\n",
    "X = data_train.drop(columns=\"Machine failure\")                                          #tahmin etmemizi istedikleri veri Machine daillure olduğu için bu veri çıkartılır\n",
    "y = data_train[\"Machine failure\"]                                                       #tahmin edeceğimiz veri ayrı seçilir\n",
    "\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.3,random_state=0)       #train test kümelerine ayırır verinin %25 i test için ayırır random_state ise seed vermek için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95500, 13), (40929, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape              #ayrılan verilerin şeklini verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler          #veriyi daha rahat işlemesi için bir aralığa sıkıştırır veri 0 ile 1 arasında olur\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val= scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation: 0.9526\n",
      "Random Forest Cross-Validation: 0.9398\n",
      "KNN Cross-Validation: 0.8897\n",
      "Logistic Regression Cross-Validation: 0.9333\n",
      "Decision Tree Cross-Validation: 0.8817\n",
      "SVM Cross-Validation: 0.9191\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()                                                                     #veri XGBClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'XGBoost Cross-Validation: {xgb_scores.mean():.4f}')\n",
    "\n",
    "rf_model = RandomForestClassifier()                                                                 #veri RandomForestClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Random Forest Cross-Validation: {rf_scores.mean():.4f}')\n",
    "\n",
    "knn_model = KNeighborsClassifier()                                                                  #veri KNeighborsClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "knn_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'KNN Cross-Validation: {knn_scores.mean():.4f}')\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight = 'balanced')                                        #veri LogisticRegression kullanılarak eğitilir ve sonuç print edilir\n",
    "logreg_scores = cross_val_score(logreg_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Logistic Regression Cross-Validation: {logreg_scores.mean():.4f}')\n",
    "\n",
    "dt_model = DecisionTreeClassifier()                                                                 #veri DecisionTreeClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "dt_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'Decision Tree Cross-Validation: {dt_scores.mean():.4f}')\n",
    "\n",
    "svm_model = SVC(probability=True)                                                                   #veri SVC kullanılarak eğitilir ve sonuç print edilir\n",
    "svm_scores = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='roc_auc_ovo')\n",
    "print(f'SVM Cross-Validation: {svm_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation: 0.9583\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()                                                                     #veri XGBClassifier kullanılarak eğitilir ve sonuç print edilir\n",
    "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=500, scoring='roc_auc_ovo')\n",
    "print(f'XGBoost Cross-Validation: {xgb_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_predict\u001b[38;5;241m=\u001b[39m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Basri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\Basri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1169\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1170\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1171\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1172\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1173\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1174\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1175\u001b[0m         )\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Basri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:725\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "Y_predict=xgb_model.predict(data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
